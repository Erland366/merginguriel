"""
Data loading functionality for MergingUriel results analysis.

This module handles loading and preprocessing of experiment results,
N-x-N evaluation matrices, and merge details.
"""

import os
import re
import glob
import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Any

from merginguriel.naming_config import naming_manager


class ResultsDataLoader:
    """Handles loading of all result data for analysis."""

    def __init__(
        self,
        results_dir: str = ".",
        num_languages_filter: Optional[List[int]] = None,
        similarity_types: Optional[List[str]] = None,
    ):
        self.results_dir = Path(results_dir)
        self.merged_models_path = self.results_dir / "merged_models"
        self.ensemble_results_path = self.results_dir / "ensemble_results"
        self.experiment_results_dir = self.results_dir
        self.num_languages_filter = num_languages_filter
        self.similarity_types = similarity_types

        # Data storage
        self.results_dfs: Dict[str, pd.DataFrame] = {}
        self.nxn_matrices: Dict[str, pd.DataFrame] = {}
        self.experiment_results: Dict[str, Dict] = {}
        self.main_results_df: Optional[pd.DataFrame] = None

    def load_all_data(self) -> None:
        """Load all available CSV files and N-x-N evaluation data."""
        print("Loading data files...")

        self._load_main_results()
        self._load_nxn_matrices()
        self._load_experiment_directories()

        print(f"Loaded main results for {len(self.main_results_df)} entries")
        if self.nxn_matrices:
            for fam, mat in self.nxn_matrices.items():
                print(f"Loaded N-x-N matrix for {fam} with {len(mat)} languages")

    def _load_main_results(self) -> None:
        """Load latest comparison results from the configured directory."""
        csv_files = glob.glob(str(self.results_dir / "results_comparison_*.csv"))
        if not csv_files:
            raise FileNotFoundError(
                f"No comparison CSV files found in {self.results_dir}. "
                "Expected files named results_comparison_*.csv generated by aggregate_results."
            )

        latest_csv = max(csv_files, key=os.path.getctime)
        print(f"Loading main results from: {latest_csv}")

        self.main_results_df = pd.read_csv(
            latest_csv, na_values=["", "NA", "N/A", "null", "None"]
        )
        self.main_results_df = self.main_results_df.dropna(subset=["locale"])

    def _load_nxn_matrices(self) -> None:
        """Load per-family N-x-N evaluation data from architecture-named subdirectories."""
        repo_root = Path(__file__).resolve().parents[2]
        nxn_results_dir = repo_root / "nxn_results"

        if not nxn_results_dir.exists():
            print("Warning: No N-x-N evaluation matrix found in repo nxn_results/")
            return

        arch_dirs = sorted(nxn_results_dir.glob("*"), key=os.path.getmtime, reverse=True)

        for arch_dir in arch_dirs:
            if not arch_dir.is_dir():
                continue
            if arch_dir.name.startswith("nxn_eval_"):
                continue

            fam = self._normalize_arch(arch_dir.name)
            pattern = sorted(
                arch_dir.glob("evaluation_matrix*.csv"), key=os.path.getmtime, reverse=True
            )

            for nxn_path in pattern:
                try:
                    df = pd.read_csv(nxn_path, index_col=0).dropna()
                    self.nxn_matrices.setdefault(fam, df)
                    print(f"Loaded N-x-N evaluation for {fam} from: {nxn_path}")
                    break
                except Exception as exc:
                    print(f"Warning: failed to load {nxn_path}: {exc}")

        if not self.nxn_matrices:
            print("Warning: No N-x-N evaluation matrix found in repo nxn_results/")

    def _normalize_arch(self, name: str) -> str:
        """Normalize architecture name by replacing underscores with hyphens."""
        return name.replace("_", "-")

    def _load_experiment_directories(self) -> None:
        """Load results from individual experiment directories."""
        print("Loading experiment directories...")

        direct_results_file = self.experiment_results_dir / "results.json"
        if direct_results_file.exists():
            result = self._load_experiment_result(self.experiment_results_dir)
            if result:
                if self._passes_similarity_filter(result):
                    self.experiment_results["direct"] = result

        exp_patterns = [
            "*_*lang_*",
            "ensemble_*",
            "baseline_*",
            "*_merge_*",
        ]

        for pattern in exp_patterns:
            for exp_dir in self.experiment_results_dir.glob(pattern):
                if exp_dir.is_dir():
                    result = self._load_experiment_result(exp_dir)
                    if result and self._passes_similarity_filter(result):
                        self.experiment_results[exp_dir.name] = result

        print(f"Loaded {len(self.experiment_results)} experiment results")

    def _passes_similarity_filter(self, result: Dict) -> bool:
        """Check if result passes the similarity type filter."""
        if self.similarity_types is None:
            return True
        return result.get("similarity_type") in self.similarity_types

    def _load_experiment_result(self, exp_dir: Path) -> Optional[Dict]:
        """Load result from a single experiment directory."""
        results_file = exp_dir / "results.json"
        if not results_file.exists():
            return None

        with open(results_file, "r") as f:
            data = json.load(f)

        parsed = naming_manager.parse_results_dir_name(exp_dir.name)
        similarity_type = parsed["similarity_type"]
        model_family = parsed["model_family"]
        num_languages = parsed["num_languages"]
        locale = parsed["locale"]
        method = parsed["method"]
        experiment_type = parsed["experiment_type"]

        eval_info = data.get("evaluation_info", {})
        performance = data.get("performance", {})
        model_info = data.get("model_info", {})

        accuracy = performance.get("accuracy", 0)
        if accuracy == 0:
            accuracy = eval_info.get("accuracy", 0)

        return {
            "directory": exp_dir.name,
            "type": self._detect_experiment_type(exp_dir.name),
            "similarity_type": similarity_type,
            "model_family": model_family,
            "num_languages": num_languages,
            "target_locale": locale or eval_info.get("locale") or data.get("target_locale"),
            "method": method,
            "experiment_type": experiment_type,
            "accuracy": accuracy,
            "baseline_accuracy": performance.get("baseline_accuracy", 0)
            or eval_info.get("baseline_accuracy", 0),
            "experiment_info": eval_info,
            "model_info": model_info,
            "merge_details": self._load_merge_details(exp_dir)
            if "merge" in exp_dir.name
            else None,
            "model_family_name": eval_info.get("model_family_name") or model_family,
            "num_models": model_info.get("num_models") or num_languages,
        }

    def _detect_experiment_type(self, dir_name: str) -> str:
        """Detect experiment type from directory name using centralized naming system."""
        parsed = naming_manager.parse_results_dir_name(dir_name)
        experiment_type = parsed["experiment_type"]

        if experiment_type == "baseline":
            return "baseline"
        elif experiment_type == "ensemble":
            return "ensemble"
        elif experiment_type in ["merging", "iterative"]:
            return f"merge_{parsed['method']}"
        else:
            return "unknown"

    def _load_merge_details(self, exp_dir: Path) -> Optional[Dict]:
        """Load merge details from merge_details.txt file."""
        merge_details_file = exp_dir / "merge_details.txt"
        if not merge_details_file.exists():
            return None

        with open(merge_details_file, "r") as f:
            content = f.read()

        locale_pattern = re.compile(r"^\s*- Locale:\s*([a-zA-Z]{2}-[a-zA-Z]{2})", re.MULTILINE)
        locales = locale_pattern.findall(content)

        weight_pattern = re.compile(
            r"^\s*- Locale:\s*([a-zA-Z]{2}-[a-zA-Z]{2}).*?Weight:\s*([0-9.]+)",
            re.MULTILINE | re.DOTALL,
        )
        weight_matches = weight_pattern.findall(content)
        weights = {locale: float(weight) for locale, weight in weight_matches}

        return {
            "source_locales": locales,
            "weights": weights,
            "content": content,
        }

    def get_nxn_for_family(self, model_family: Optional[str]) -> Optional[pd.DataFrame]:
        """Return the NxN matrix for the given family, if available."""
        if not model_family or not self.nxn_matrices:
            return None
        for fam_key, mat in self.nxn_matrices.items():
            if model_family == fam_key:
                return mat
            if model_family.startswith(fam_key) or fam_key.startswith(model_family):
                return mat
        return None

    def get_zero_shot_scores(
        self, target_locale: str, source_locales: List[str], model_family: Optional[str]
    ) -> Dict[str, float]:
        """Get zero-shot scores for target locale from source locales using family-matched NxN."""
        nxn = self.get_nxn_for_family(model_family)
        if nxn is None:
            return {}

        scores = {}
        for locale in source_locales:
            if locale in nxn.index and target_locale in nxn.columns:
                score = nxn.loc[locale, target_locale]
                if not pd.isna(score):
                    scores[locale] = float(score)

        return scores

    def get_best_source_performance(
        self, target_locale: str, source_locales: List[str], model_family: Optional[str] = None
    ) -> Optional[float]:
        """Get the best performance among the actual source languages used for a target locale."""
        zero_shot_scores = self.get_zero_shot_scores(target_locale, source_locales, model_family)
        if zero_shot_scores:
            return max(zero_shot_scores.values())
        return None

    def get_best_overall_zero_shot(
        self, target_locale: str, model_family: Optional[str]
    ) -> Optional[float]:
        """Get best zero-shot accuracy for target across all locales (excluding target)."""
        nxn = self.get_nxn_for_family(model_family)
        if nxn is None or target_locale not in nxn.columns:
            return None
        col = nxn[target_locale]
        col = col.drop(target_locale, errors="ignore")
        col = col[col.notna()]
        if col.empty:
            return None
        return float(col.max())

    def find_merge_locales(self, target_locale: str, merge_type: str = "similarity") -> List[str]:
        """Find which locales were used for merging a target language."""
        merge_dir = None
        merge_details_file = None

        for similarity_type in ["URIEL", "REAL"]:
            for exp_dir in self.merged_models_path.glob(
                f"{merge_type}_{similarity_type}_merge_{target_locale}_*merged"
            ):
                if exp_dir.is_dir():
                    merge_dir = exp_dir
                    merge_details_file = merge_dir / "merge_details.txt"
                    break
            if merge_dir:
                break

        if merge_dir is None:
            for exp_dir in self.merged_models_path.glob(
                f"{merge_type}_merge_{target_locale}_*merged"
            ):
                if exp_dir.is_dir():
                    merge_dir = exp_dir
                    merge_details_file = merge_dir / "merge_details.txt"
                    break

        if merge_dir is None:
            merge_dir = self.merged_models_path / f"{merge_type}_merge_{target_locale}"
            merge_details_file = merge_dir / "merge_details.txt"

        if not merge_details_file.exists():
            return []

        with open(merge_details_file, "r") as f:
            content = f.read()

        locale_pattern = re.compile(r"^\s*- Locale:\s*([a-zA-Z]{2}-[a-zA-Z]{2})", re.MULTILINE)
        return locale_pattern.findall(content)

    def extract_num_languages_from_details(
        self, target_locale: str, merge_type: str
    ) -> Optional[int]:
        """Extract number of languages from merge_details.txt files."""
        merge_patterns = []
        for similarity_type in ["URIEL", "REAL"]:
            merge_patterns.append(
                f"merged_models/{merge_type}_{similarity_type}_merge_{target_locale}_*merged/merge_details.txt"
            )
        merge_patterns.extend(
            [
                f"merged_models/{merge_type}_merge_{target_locale}_*merged/merge_details.txt",
                f"merged_models/{merge_type}_merge_{target_locale}/merge_details.txt",
            ]
        )

        merge_details_file = None
        for pattern in merge_patterns:
            matches = glob.glob(pattern)
            if matches:
                merge_details_file = matches[0]
                break

        if not merge_details_file:
            return None

        with open(merge_details_file, "r") as f:
            content = f.read()

        model_pattern = re.compile(r"^\s*\d+\.\s*Model:", re.MULTILINE)
        matches = model_pattern.findall(content)
        return len(matches) if matches else None

    def extract_source_locales_from_details(
        self,
        target_locale: str,
        model_family: Optional[str] = None,
        num_languages: Optional[int] = None,
    ) -> List[str]:
        """Extract source locales from merge_details.txt; fallback to NxN top-K when missing."""
        merge_patterns = []

        for similarity_type in ["URIEL", "REAL"]:
            merge_patterns.extend(
                [
                    f"merged_models/*_{similarity_type}_merge_{target_locale}_*merged/merge_details.txt",
                    f"merged_models/similarity_{similarity_type}_merge_{target_locale}_*merged/merge_details.txt",
                    f"merged_models/average_{similarity_type}_merge_{target_locale}_*merged/merge_details.txt",
                ]
            )

        merge_patterns.extend(
            [
                f"merged_models/*merge_{target_locale}_*merged/merge_details.txt",
                f"merged_models/similarity_merge_{target_locale}_*merged/merge_details.txt",
                f"merged_models/average_merge_{target_locale}_*merged/merge_details.txt",
                f"merged_models/similarity_merge_{target_locale}/merge_details.txt",
                f"merged_models/average_merge_{target_locale}/merge_details.txt",
                f"merged_models/*merge_{target_locale}/merge_details.txt",
            ]
        )

        for pattern in merge_patterns:
            merge_details_files = list(self.results_dir.glob(pattern))
            if merge_details_files:
                merge_details_file = merge_details_files[0]
                with open(merge_details_file, "r") as f:
                    content = f.read()

                locale_pattern = re.compile(
                    r"^\s*- Locale:\s*([a-zA-Z]{2}-[a-zA-Z]{2})", re.MULTILINE
                )
                locales = locale_pattern.findall(content)
                if locales:
                    return locales

        for exp_dir in self.results_dir.glob(f"merged_models/*{target_locale}"):
            if exp_dir.is_dir():
                merge_details_file = exp_dir / "merge_details.txt"
                if merge_details_file.exists():
                    with open(merge_details_file, "r") as f:
                        content = f.read()

                    locale_pattern = re.compile(
                        r"^\s*- Locale:\s*([a-zA-Z]{2}-[a-zA-Z]{2})", re.MULTILINE
                    )
                    locales = locale_pattern.findall(content)
                    if locales:
                        return locales

        source_locales = set()
        for exp_key, exp_result in self.experiment_results.items():
            if exp_result.get("target_locale") == target_locale:
                exp_source_locales = exp_result.get("source_locales", [])
                if exp_source_locales:
                    source_locales.update(exp_source_locales)

        if source_locales:
            return list(source_locales)

        nxn = self.get_nxn_for_family(model_family)
        if nxn is not None and target_locale in nxn.columns:
            target_column = nxn[target_locale].drop(target_locale, errors="ignore")
            top_k = num_languages if num_languages is not None else 5
            inferred = target_column.nlargest(top_k).index.tolist()
            print(f"Warning: Using inferred sources from NxN for {target_locale}: {inferred}")
            return inferred

        print(f"Warning: No NxN matrix available to infer source locales for {target_locale}")
        return []

    def get_num_languages_from_merged_models(
        self, locale: str, method: str
    ) -> Optional[int]:
        """Extract num_languages from actual merged_models folder names."""
        merged_models_path = self.results_dir / "merged_models"

        if not merged_models_path.exists():
            return None

        base_method = method
        match = re.match(r"(.+?)_(\d+)lang$", method)
        if match:
            base_method = match.group(1)

        for similarity_type in ["URIEL", "REAL"]:
            pattern = f"{base_method}_{similarity_type}_merge_{locale}_(\\d+)merged"
            for entry in merged_models_path.iterdir():
                if entry.is_dir():
                    match = re.search(pattern, entry.name)
                    if match:
                        return int(match.group(1))

        pattern = f"{base_method}_merge_{locale}_(\\d+)merged"
        for entry in merged_models_path.iterdir():
            if entry.is_dir():
                match = re.search(pattern, entry.name)
                if match:
                    return int(match.group(1))

        return None

    def extract_similarity_type(self, dir_name: str) -> str:
        """Extract similarity type (URIEL/REAL) from directory name."""
        parsed = naming_manager.parse_results_dir_name(dir_name)
        similarity_type = parsed["similarity_type"]
        return similarity_type if similarity_type else "unknown"
